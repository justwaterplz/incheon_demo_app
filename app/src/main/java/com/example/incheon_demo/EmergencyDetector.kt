package com.example.incheon_demo

import android.content.Context
import android.graphics.Bitmap
import android.media.MediaMetadataRetriever
import android.util.Log
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.withContext
import org.pytorch.IValue
import org.pytorch.LiteModuleLoader
import org.pytorch.Module
import org.pytorch.Tensor
import org.pytorch.torchvision.TensorImageUtils
import java.io.File
import kotlin.math.exp

class ActionClassifier(private val context: Context) {
    
    companion object {
        private const val TAG = "ActionClassifier"
        private const val MODEL_NAME = "8cls.ptl"  // ê¸°ì¡´ ëª¨ë¸ë¡œ ì„ì‹œ ë³µì›
        private const val INPUT_SIZE = 112  // ì›ë³¸ Python ëª¨ë¸ê³¼ ì¼ì¹˜ (112x112)
        private const val NUM_FRAMES = 16   // 3D ResNet ìŠ¤íƒ€ì¼ ì—°ì† í”„ë ˆì„
        private const val NUM_CLASSES = 8   // AI ëª¨ë¸ì˜ í´ë˜ìŠ¤ ìˆ˜ (baseline_3d_resnetsì™€ í˜¸í™˜)
        
        // AI ëª¨ë¸ì˜ 8ê°œ í´ë˜ìŠ¤ ë ˆì´ë¸”
        private val CLASS_LABELS = arrayOf(
            "í­í–‰",        // 0: assault
            "ì†Œë§¤ì¹˜ê¸°",    // 1: burglar  
            "ë°ì´íŠ¸ í­ë ¥", // 2: date
            "ì·¨ê°",        // 3: drunken
            "ì‹¸ì›€",        // 4: fight
            "ë‚©ì¹˜",        // 5: kidnap
            "ì •ìƒ",        // 6: none
            "ê°•ë„"         // 7: robbery
        )
        
        // ì‘ê¸‰ìƒí™©ìœ¼ë¡œ ê°„ì£¼í•  í´ë˜ìŠ¤ ì¸ë±ìŠ¤ë“¤
        private val EMERGENCY_CLASS_INDICES = setOf(0, 1, 2, 3, 4, 5, 7)  // ì •ìƒ(6)ì„ ì œì™¸í•œ ëª¨ë“  í´ë˜ìŠ¤
    }
    
    private var model: Module? = null
    private var isModelLoaded = false
    
    data class ActionAnalysisResult(
        val isEmergency: Boolean,
        val topPredictions: List<ClassPrediction>,  // Top3 ì˜ˆì¸¡ ê²°ê³¼
        val confidence: Float,
        val totalSegments: Int,
        val emergencySegments: Int,
        val dominantAction: String
    )
    
    data class ClassPrediction(
        val classIndex: Int,
        val className: String,
        val confidence: Float,
        val isEmergency: Boolean
    )
    
    data class SegmentAnalysisResult(
        val predictions: List<ClassPrediction>,
        val isEmergency: Boolean
    )
    
    interface AnalysisProgressCallback {
        fun onProgressUpdate(progress: Int, status: String)
    }
    
    init {
        try {
            Log.d(TAG, "ğŸš€ ActionClassifier ì´ˆê¸°í™” ì‹œì‘")
            loadModel()
            Log.d(TAG, "âœ… ActionClassifier ì´ˆê¸°í™” ì™„ë£Œ")
        } catch (e: Exception) {
            Log.e(TAG, "ğŸ’¥ ActionClassifier ì´ˆê¸°í™” ì‹¤íŒ¨: ${e.message}", e)
            isModelLoaded = false
            model = null
        }
    }
    
    private fun loadModel() {
        try {
            Log.d(TAG, "ğŸš€ 8í´ë˜ìŠ¤ ë™ì‘ ì¸ì‹ ëª¨ë¸ ë¡œë”© ì‹œì‘: $MODEL_NAME")
            
            // assets íŒŒì¼ ì¡´ì¬ í™•ì¸
            val assetManager = context.assets
            val assetList = assetManager.list("")
            Log.d(TAG, "ğŸ“ Assets íŒŒì¼ ëª©ë¡: ${assetList?.joinToString(", ")}")
            
            // ëª¨ë¸ íŒŒì¼ í¬ê¸° í™•ì¸
            val inputStream = assetManager.open(MODEL_NAME)
            val fileSize = inputStream.available()
            inputStream.close()
            Log.d(TAG, "ğŸ“„ ëª¨ë¸ íŒŒì¼ í¬ê¸°: ${fileSize / (1024 * 1024)}MB")
            
            if (fileSize < 1000000) { // 1MB ë¯¸ë§Œì´ë©´ ë¬¸ì œ
                throw RuntimeException("ëª¨ë¸ íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŒ: ${fileSize} bytes")
            }
            
            // assetsì—ì„œ ëª¨ë¸ íŒŒì¼ ë³µì‚¬
            val modelPath = ModelUtils.assetFilePath(context, MODEL_NAME)
            Log.d(TAG, "ğŸ“‚ ëª¨ë¸ íŒŒì¼ ê²½ë¡œ: $modelPath")
            
            // ëª¨ë¸ ë¡œë”©
            model = LiteModuleLoader.load(modelPath)
            
            if (model == null) {
                throw RuntimeException("LiteModuleLoader.load()ê°€ nullì„ ë°˜í™˜í•¨")
            }
            
            // ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì¶”ë¡  ì‹¤í–‰ (ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰)
            try {
                testModelInference()
            } catch (e: Exception) {
                Log.w(TAG, "âš ï¸ ëª¨ë¸ í…ŒìŠ¤íŠ¸ëŠ” ì‹¤íŒ¨í–ˆì§€ë§Œ ë¡œë”©ì€ ì™„ë£Œë¨: ${e.message}")
            }
            
            isModelLoaded = true
            Log.d(TAG, "ğŸ‰ 8í´ë˜ìŠ¤ ë™ì‘ ì¸ì‹ ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
            
        } catch (e: Exception) {
            Log.e(TAG, "ğŸ’¥ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: ${e.message}", e)
            isModelLoaded = false
            model = null
            throw RuntimeException("ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: ${e.message}", e)
        }
    }
    
    private fun testModelInference() {
        try {
            if (model == null) return
            
            Log.d(TAG, "ğŸ§ª ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì¶”ë¡  ì‹œì‘ (4D/5D í˜¼í•©)")
            
            // ì—¬ëŸ¬ ì°¨ì›ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•´ë³´ê¸° (112x112 ê¸°ì¤€) - 5D ìš°ì„ 
            val testCases = listOf(
                // Case 1: 5D í…ì„œ (3D ResNetì˜ ì˜¬ë°”ë¥¸ ì…ë ¥) - ìµœìš°ì„ 
                Triple(
                    "5D-TrueCNN",
                    longArrayOf(1, 3, NUM_FRAMES.toLong(), INPUT_SIZE.toLong(), INPUT_SIZE.toLong()),
                    3 * NUM_FRAMES * INPUT_SIZE * INPUT_SIZE
                ),
                // Case 2: 4D í…ì„œ (í”„ë ˆì„ì„ ì±„ë„ë¡œ flatten) - ë°±ì—…ìš©
                Triple(
                    "4D-FramesToChannels", 
                    longArrayOf(1, (3 * NUM_FRAMES).toLong(), INPUT_SIZE.toLong(), INPUT_SIZE.toLong()),
                    3 * NUM_FRAMES * INPUT_SIZE * INPUT_SIZE
                ),
                // Case 3: 4D í…ì„œ (ë‹¨ì¼ í”„ë ˆì„) - ìµœí›„ ìˆ˜ë‹¨
                Triple(
                    "4D-SingleFrame", 
                    longArrayOf(1, 3, INPUT_SIZE.toLong(), INPUT_SIZE.toLong()),
                    3 * INPUT_SIZE * INPUT_SIZE
                )
            )
            
            var testSuccess = false
            var successCase = ""
            
            for ((caseName, shape, dataSize) in testCases) {
                try {
                    Log.d(TAG, "ğŸ” í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤: $caseName, í˜•íƒœ: ${shape.contentToString()}")
                    
                    // í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë°ì´í„° ìƒì„± (ImageNet ì •ê·œí™”ëœ ê°’)
                    val testData = FloatArray(dataSize) { i ->
                        when (i % 3) {
                            0 -> (0.485f - 0.485f) / 0.229f  // R ì±„ë„ í‰ê· ê°’
                            1 -> (0.456f - 0.456f) / 0.224f  // G ì±„ë„ í‰ê· ê°’
                            else -> (0.406f - 0.406f) / 0.225f  // B ì±„ë„ í‰ê· ê°’
                        }
                    }
                    
                    val testInput = org.pytorch.Tensor.fromBlob(testData, shape)
                    
                    // ëª¨ë¸ ì¶”ë¡  ì‹¤í–‰
                    val output = model!!.forward(IValue.from(testInput)).toTensor()
                    val scores = output.dataAsFloatArray
                    
                    Log.d(TAG, "âœ… $caseName í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
                    Log.d(TAG, "   - ì…ë ¥ í˜•íƒœ: ${shape.contentToString()}")
                    Log.d(TAG, "   - ì¶œë ¥ í´ë˜ìŠ¤ ìˆ˜: ${scores.size}")
                    
                    // Softmax ì ìš©í•˜ì—¬ í™•ë¥  ê³„ì‚°
                    val probabilities = softmax(scores)
                    
                    Log.d(TAG, "ğŸ” $caseName í…ŒìŠ¤íŠ¸ ì¶œë ¥ ë¶„ì„:")
                    probabilities.take(Math.min(5, probabilities.size)).forEachIndexed { idx, prob ->
                        val className = if (idx < CLASS_LABELS.size) CLASS_LABELS[idx] else "í´ë˜ìŠ¤$idx"
                        Log.d(TAG, "   í´ë˜ìŠ¤ $idx ($className): ${String.format("%.2f", prob * 100)}%")
                    }
                    
                    testSuccess = true
                    successCase = caseName
                    break // ì²« ë²ˆì§¸ ì„±ê³µí•œ ì¼€ì´ìŠ¤ë¡œ ê²°ì •
                    
                } catch (e: Exception) {
                    Log.w(TAG, "âš ï¸ $caseName ì‹¤íŒ¨: ${e.message}")
                }
            }
            
            if (testSuccess) {
                Log.d(TAG, "ğŸ‰ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ! ì„±ê³µí•œ í˜•íƒœ: $successCase")
            } else {
                Log.w(TAG, "âš ï¸ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‹¤íŒ¨ - ì‹¤ì œ ì¶”ë¡  ì‹œ ë™ì ìœ¼ë¡œ ì²˜ë¦¬")
            }
            
        } catch (e: Exception) {
            Log.w(TAG, "âš ï¸ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: ${e.message}")
            Log.w(TAG, "   ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: ${e.stackTraceToString()}")
            // í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
        }
    }
    
    suspend fun analyzeVideoWithProgress(
        videoPath: String,
        callback: AnalysisProgressCallback
    ): ActionAnalysisResult = withContext(Dispatchers.IO) {
        
        if (!isModelLoaded || model == null) {
            val errorMsg = "ğŸš¨ AI ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            Log.e(TAG, errorMsg)
            callback.onProgressUpdate(100, "ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨")
            throw RuntimeException(errorMsg)
        }
        
        try {
            callback.onProgressUpdate(0, "ì˜ìƒ ë¶„ì„ ì¤€ë¹„ ì¤‘...")
            
            // ë¹„ë””ì˜¤ íŒŒì¼ ê²€ì¦
            val videoFile = File(videoPath)
            Log.d(TAG, "ğŸ” ë¹„ë””ì˜¤ íŒŒì¼ ê²€ì¦:")
            Log.d(TAG, "   - íŒŒì¼ ê²½ë¡œ: $videoPath")
            Log.d(TAG, "   - íŒŒì¼ ì¡´ì¬: ${videoFile.exists()}")
            Log.d(TAG, "   - íŒŒì¼ í¬ê¸°: ${videoFile.length()} bytes")
            Log.d(TAG, "   - ì ˆëŒ€ ê²½ë¡œ: ${videoFile.absolutePath}")
            Log.d(TAG, "   - ì½ê¸° ê¶Œí•œ: ${videoFile.canRead()}")
            
            if (!videoFile.exists()) {
                val parentDir = videoFile.parentFile
                Log.e(TAG, "âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ!")
                Log.e(TAG, "   - ë¶€ëª¨ ë””ë ‰í† ë¦¬: ${parentDir?.absolutePath}")
                Log.e(TAG, "   - ë¶€ëª¨ ë””ë ‰í† ë¦¬ ì¡´ì¬: ${parentDir?.exists()}")
                if (parentDir?.exists() == true) {
                    Log.e(TAG, "   - ë””ë ‰í† ë¦¬ ë‚´ìš©: ${parentDir.listFiles()?.map { it.name }?.joinToString(", ")}")
                }
                throw RuntimeException("ë¹„ë””ì˜¤ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: $videoPath")
            }
            
            if (videoFile.length() == 0L) {
                Log.e(TAG, "âŒ íŒŒì¼ í¬ê¸°ê°€ 0 bytes!")
                throw RuntimeException("ë¹„ë””ì˜¤ íŒŒì¼ì´ ì†ìƒë¨ (í¬ê¸°: 0 bytes)")
            }
            
            Log.d(TAG, "âœ… ë¹„ë””ì˜¤ íŒŒì¼ ê²€ì¦ ì™„ë£Œ!")
            
            // ì—°ì† í”„ë ˆì„ ì„¸ê·¸ë¨¼íŠ¸ë“¤ ì¶”ì¶œ
            val segments = extractVideoSegments(videoPath, callback)
            
            if (segments.isEmpty()) {
                throw RuntimeException("ì¶”ì¶œëœ í”„ë ˆì„ ì„¸ê·¸ë¨¼íŠ¸ê°€ ì—†ìŒ")
            }
            
            callback.onProgressUpdate(50, "ë™ì‘ ë¶„ì„ ì¤‘...")
            
            // ê° ì„¸ê·¸ë¨¼íŠ¸ì— ëŒ€í•´ ë™ì‘ ë¶„ì„
            val segmentResults = mutableListOf<SegmentAnalysisResult>()
            val allPredictions = mutableListOf<ClassPrediction>()
            var emergencySegmentCount = 0
            
            segments.forEachIndexed { index, segment ->
                try {
                    val result = analyzeSegment(segment)
                    segmentResults.add(result)
                    allPredictions.addAll(result.predictions)
                    
                    if (result.isEmergency) {
                        emergencySegmentCount++
                    }
                    
                    val progress = 50 + (index * 40 / segments.size)
                    callback.onProgressUpdate(progress, "ì„¸ê·¸ë¨¼íŠ¸ ${index + 1}/${segments.size} ë¶„ì„ ì™„ë£Œ")
                    
                } catch (e: Exception) {
                    Log.w(TAG, "ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„ ì‹¤íŒ¨: ${e.message}")
                }
            }
            
            // Top3 ì˜ˆì¸¡ ê²°ê³¼ ê³„ì‚°
            val classCounts = mutableMapOf<Int, Float>()
            allPredictions.forEach { pred ->
                classCounts[pred.classIndex] = classCounts.getOrDefault(pred.classIndex, 0f) + pred.confidence
            }
            
            val topPredictions = classCounts.entries
                .sortedByDescending { it.value }
                .take(3)
                .map { (classIndex, totalConfidence) ->
                    ClassPrediction(
                        classIndex = classIndex,
                        className = if (classIndex < CLASS_LABELS.size) CLASS_LABELS[classIndex] else "í´ë˜ìŠ¤$classIndex",
                        confidence = totalConfidence / allPredictions.size,
                        isEmergency = classIndex in EMERGENCY_CLASS_INDICES
                    )
                }
            
            // ìµœì¢… íŒì •
            val isEmergency = topPredictions.any { it.isEmergency && it.confidence > 0.3f } ||
                              (emergencySegmentCount.toFloat() / segments.size) > 0.2f
            
            val dominantAction = topPredictions.firstOrNull()?.className ?: "ì•Œ ìˆ˜ ì—†ìŒ"
            val maxConfidence = topPredictions.firstOrNull()?.confidence ?: 0f
            
            Log.d(TAG, "ğŸ”” ìµœì¢… ë¶„ì„ ê²°ê³¼:")
            Log.d(TAG, "   - ì´ ì„¸ê·¸ë¨¼íŠ¸: ${segments.size}")
            Log.d(TAG, "   - ì‘ê¸‰ ì„¸ê·¸ë¨¼íŠ¸: $emergencySegmentCount")
            Log.d(TAG, "   - ì£¼ìš” ë™ì‘: $dominantAction")
            Log.d(TAG, "   - ìµœì¢… íŒì •: ${if (isEmergency) "ğŸš¨ ì‘ê¸‰ìƒí™©" else "âœ… ì •ìƒ"}")
            
            callback.onProgressUpdate(100, "ë¶„ì„ ì™„ë£Œ!")
            
            return@withContext ActionAnalysisResult(
                isEmergency = isEmergency,
                topPredictions = topPredictions,
                confidence = maxConfidence,
                totalSegments = segments.size,
                emergencySegments = emergencySegmentCount,
                dominantAction = dominantAction
            )
            
        } catch (e: Exception) {
            Log.e(TAG, "ì˜ìƒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: ${e.message}", e)
            callback.onProgressUpdate(100, "ë¶„ì„ ì˜¤ë¥˜ ë°œìƒ")
            throw e
        }
    }
    
    private fun extractVideoSegments(videoPath: String, callback: AnalysisProgressCallback): List<List<Bitmap>> {
        val segments = mutableListOf<List<Bitmap>>()
        val retriever = MediaMetadataRetriever()
        
        try {
            retriever.setDataSource(videoPath)
            val durationStr = retriever.extractMetadata(MediaMetadataRetriever.METADATA_KEY_DURATION)
            val duration = durationStr?.toLongOrNull() ?: 10000L
            
            // ì„¸ê·¸ë¨¼íŠ¸ ê°„ê²© ê³„ì‚° (ê²¹ì¹˜ëŠ” êµ¬ê°„ í¬í•¨)
            val segmentDuration = 2000L  // 2ì´ˆ ì„¸ê·¸ë¨¼íŠ¸
            val stepSize = 1000L         // 1ì´ˆì”© ì´ë™ (50% ê²¹ì¹¨)
            
            var currentTime = 0L
            var segmentIndex = 0
            
            while (currentTime + segmentDuration <= duration) {
                val frames = mutableListOf<Bitmap>()
                val frameInterval = segmentDuration / NUM_FRAMES
                
                for (i in 0 until NUM_FRAMES) {
                    val frameTime = currentTime + (i * frameInterval)
                    try {
                        val frame = retriever.getFrameAtTime(
                            frameTime * 1000, // ë§ˆì´í¬ë¡œì´ˆë¡œ ë³€í™˜
                            MediaMetadataRetriever.OPTION_CLOSEST_SYNC
                        )
                        frame?.let { frames.add(it) }
                    } catch (e: Exception) {
                        Log.w(TAG, "í”„ë ˆì„ ì¶”ì¶œ ì‹¤íŒ¨ at ${frameTime}ms: ${e.message}")
                    }
                }
                
                // 16í”„ë ˆì„ì´ ëª¨ë‘ ì¶”ì¶œë˜ì—ˆì„ ë•Œë§Œ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ì¶”ê°€
                if (frames.size == NUM_FRAMES) {
                    segments.add(frames)
                    segmentIndex++
                }
                
                currentTime += stepSize
                
                val progress = 20 + (currentTime * 30 / duration).toInt()
                callback.onProgressUpdate(progress, "ì„¸ê·¸ë¨¼íŠ¸ ì¶”ì¶œ ì¤‘ ($segmentIndex)")
            }
            
        } finally {
            retriever.release()
        }
        
        Log.d(TAG, "ğŸ“¹ ì´ ${segments.size}ê°œ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ì¶œ ì™„ë£Œ")
        return segments
    }
    
    private fun analyzeSegment(frames: List<Bitmap>): SegmentAnalysisResult {
        try {
            // í…ì„œ ìƒì„± ì‹œë„
            val inputTensor = createInputTensor(frames)
            
            // ëª¨ë¸ ì¶”ë¡  ì‹œë„
            val outputTensor = model!!.forward(IValue.from(inputTensor)).toTensor()
            val scores = outputTensor.dataAsFloatArray
            
            Log.d(TAG, "ğŸ” ì„¸ê·¸ë¨¼íŠ¸ ì¶”ë¡  ì„±ê³µ: ì¶œë ¥ í¬ê¸°=${scores.size}")
            
            // Softmaxë¡œ í™•ë¥  ë³€í™˜
            val probabilities = softmax(scores)
            
            // Top3 ì˜ˆì¸¡ ìƒì„±
            val predictions = probabilities.indices
                .sortedByDescending { probabilities[it] }
                .take(3)
                .map { classIndex ->
                    ClassPrediction(
                        classIndex = classIndex,
                        className = if (classIndex < CLASS_LABELS.size) CLASS_LABELS[classIndex] else "í´ë˜ìŠ¤$classIndex",
                        confidence = probabilities[classIndex],
                        isEmergency = classIndex in EMERGENCY_CLASS_INDICES
                    )
                }
            
            val isEmergency = predictions.any { it.isEmergency && it.confidence > 0.4f }
            
            Log.d(TAG, "ğŸ¯ ì„¸ê·¸ë¨¼íŠ¸ ê²°ê³¼: ${predictions.firstOrNull()?.className ?: "ì•Œìˆ˜ì—†ìŒ"} (${String.format("%.1f", (predictions.firstOrNull()?.confidence ?: 0f) * 100)}%)")
            
            return SegmentAnalysisResult(
                predictions = predictions,
                isEmergency = isEmergency
            )
            
        } catch (e: Exception) {
            Log.w(TAG, "âš ï¸ ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„ ì‹¤íŒ¨: ${e.message}")
            
            // ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜ (ì •ìƒí™œë™ìœ¼ë¡œ ê°€ì •)
            return SegmentAnalysisResult(
                predictions = listOf(
                    ClassPrediction(6, "ì •ìƒí™œë™", 0.5f, false),
                    ClassPrediction(0, "ì•Œìˆ˜ì—†ìŒ1", 0.3f, false),
                    ClassPrediction(1, "ì•Œìˆ˜ì—†ìŒ2", 0.2f, false)
                ),
                isEmergency = false
            )
        }
    }
    
    private fun createInputTensor(frames: List<Bitmap>): Tensor {
        try {
            Log.d(TAG, "ğŸ”„ 5D í…ì„œ ìƒì„± ì‹œì‘: ${frames.size}ê°œ í”„ë ˆì„ â†’ (1, 3, 16, 112, 112)")
            
            // 5D í…ì„œ ë°ì´í„° ë°°ì—´ ìƒì„± (B, C, T, H, W) = (1, 3, 16, 112, 112)
            val tensorData = FloatArray(3 * NUM_FRAMES * INPUT_SIZE * INPUT_SIZE)
            
            // í”„ë ˆì„ ìˆ˜ ì¡°ì • (16ê°œ ë§ì¶¤)
            val processFrames = when {
                frames.size >= NUM_FRAMES -> frames.take(NUM_FRAMES)
                frames.size > 0 -> {
                    Log.d(TAG, "âš ï¸ í”„ë ˆì„ ìˆ˜ ë¶€ì¡± (${frames.size} < $NUM_FRAMES), ë§ˆì§€ë§‰ í”„ë ˆì„ ë°˜ë³µ")
                    val extendedFrames = frames.toMutableList()
                    while (extendedFrames.size < NUM_FRAMES) {
                        extendedFrames.add(frames.last())
                    }
                    extendedFrames
                }
                else -> {
                    Log.e(TAG, "âŒ í”„ë ˆì„ì´ ì—†ìŒ!")
                    throw RuntimeException("ì…ë ¥ í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤")
                }
            }
            
            // ê° í”„ë ˆì„ì„ 5D í…ì„œ í˜•íƒœë¡œ ë°°ì¹˜ (B, C, T, H, W)
            processFrames.forEachIndexed { frameIndex, bitmap ->
                try {
                    // í”„ë ˆì„ì„ 112x112ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
                    val resizedBitmap = Bitmap.createScaledBitmap(bitmap, INPUT_SIZE, INPUT_SIZE, true)
                    
                    // í”½ì…€ ë°ì´í„° ì¶”ì¶œ
                    val pixels = IntArray(INPUT_SIZE * INPUT_SIZE)
                    resizedBitmap.getPixels(pixels, 0, INPUT_SIZE, 0, 0, INPUT_SIZE, INPUT_SIZE)
                    
                    // RGB ì±„ë„ë³„ë¡œ ImageNet ì •ê·œí™” ì ìš©
                    for (pixelIndex in pixels.indices) {
                        val pixel = pixels[pixelIndex]
                        
                        // RGB ì¶”ì¶œ (0~255)
                        val r = ((pixel shr 16) and 0xFF) / 255.0f
                        val g = ((pixel shr 8) and 0xFF) / 255.0f
                        val b = (pixel and 0xFF) / 255.0f
                        
                        // 3D ResNet ì •ê·œí™” ì ìš©: 1-2*(x/255) â†’ [-1, 1] ë²”ìœ„
                        val rNorm = 1.0f - 2.0f * r  // ì´ë¯¸ 0~1 ë²”ìœ„ì´ë¯€ë¡œ ë°”ë¡œ ì ìš©
                        val gNorm = 1.0f - 2.0f * g
                        val bNorm = 1.0f - 2.0f * b
                        
                        // 5D í…ì„œ ë°°ì¹˜: (B, C, T, H, W) = (1, 3, 16, 112, 112)
                        // ì¸ë±ìŠ¤ ê³„ì‚°: batch * (C*T*H*W) + channel * (T*H*W) + time * (H*W) + pixel
                        val frameSize = INPUT_SIZE * INPUT_SIZE  // H * W
                        val channelSize = NUM_FRAMES * frameSize  // T * H * W
                        
                        // R, G, B ì±„ë„ë³„ë¡œ ë°ì´í„° ë°°ì¹˜
                        tensorData[0 * channelSize + frameIndex * frameSize + pixelIndex] = rNorm  // R ì±„ë„
                        tensorData[1 * channelSize + frameIndex * frameSize + pixelIndex] = gNorm  // G ì±„ë„
                        tensorData[2 * channelSize + frameIndex * frameSize + pixelIndex] = bNorm  // B ì±„ë„
                    }
                    
                } catch (e: Exception) {
                    Log.e(TAG, "í”„ë ˆì„ $frameIndex ì²˜ë¦¬ ì‹¤íŒ¨: ${e.message}")
                    throw e
                }
            }
            
            // 5D í…ì„œ ìƒì„±: (1, 3, 16, 112, 112)
            val tensor = Tensor.fromBlob(
                tensorData,
                longArrayOf(1, 3, NUM_FRAMES.toLong(), INPUT_SIZE.toLong(), INPUT_SIZE.toLong())
            )
            
            Log.d(TAG, "âœ… 5D í…ì„œ ìƒì„± ì„±ê³µ!")
            Log.d(TAG, "   - í˜•íƒœ: (1, 3, $NUM_FRAMES, $INPUT_SIZE, $INPUT_SIZE)")
            Log.d(TAG, "   - ë°ì´í„° í¬ê¸°: ${tensorData.size}")
            Log.d(TAG, "   - í”„ë ˆì„ ì²˜ë¦¬: ${processFrames.size}ê°œ â†’ ì‹œê°„ì¶• ìœ ì§€")
            
            return tensor
            
        } catch (e: Exception) {
            Log.e(TAG, "ğŸ’¥ 5D í…ì„œ ìƒì„± ì‹¤íŒ¨: ${e.message}")
            throw RuntimeException("5D ì…ë ¥ í…ì„œ ìƒì„± ì‹¤íŒ¨", e)
        }
    }
    
    private fun softmax(scores: FloatArray): FloatArray {
        val maxScore = scores.maxOrNull() ?: 0.0f
        val expScores = scores.map { exp((it - maxScore).toDouble()).toFloat() }
        val sumExp = expScores.sum()
        return expScores.map { it / sumExp }.toFloatArray()
    }
    
    fun cleanup() {
        try {
            model = null
            isModelLoaded = false
            Log.d(TAG, "ActionClassifier ì •ë¦¬ ì™„ë£Œ")
        } catch (e: Exception) {
            Log.e(TAG, "ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: ${e.message}")
        }
    }
} 