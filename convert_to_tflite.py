import torch
import torch.nn as nn
import onnx
import onnx_tf
import tensorflow as tf
import numpy as np
import os

# Emergency Detection Model Architecture (same as before)
class EmergencyDetectionModel(nn.Module):
    def __init__(self, num_classes=2):
        super(EmergencyDetectionModel, self).__init__()
        
        self.features = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            
            nn.Conv2d(128, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
        )
        
        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool2d((7, 7)),
            nn.Flatten(),
            nn.Linear(256 * 7 * 7, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(512, num_classes)
        )
    
    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x

def convert_pytorch_to_tflite(model_path="model.pt", output_path="app/src/main/assets/emergency_model.tflite"):
    """
    PyTorch ëª¨ë¸ì„ TensorFlow Liteë¡œ ë³€í™˜
    ë‹¨ê³„: PyTorch â†’ ONNX â†’ TensorFlow â†’ TFLite
    """
    
    print("=== PyTorch â†’ TensorFlow Lite ë³€í™˜ ì‹œì‘ ===")
    
    try:
        # Step 1: PyTorch ëª¨ë¸ ì¤€ë¹„
        print("1. PyTorch ëª¨ë¸ ë¡œë”©...")
        model = EmergencyDetectionModel(num_classes=2)
        
        if os.path.exists(model_path):
            try:
                state_dict = torch.load(model_path, map_location='cpu')
                if isinstance(state_dict, dict):
                    model.load_state_dict(state_dict)
                else:
                    model = state_dict
                print("âœ“ ëª¨ë¸ íŒŒë¼ë¯¸í„° ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸ íŒŒë¼ë¯¸í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
                print("ê¸°ë³¸ ëª¨ë¸ êµ¬ì¡° ì‚¬ìš©")
        else:
            print(f"âš ï¸ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {model_path}")
            print("ê¸°ë³¸ ëª¨ë¸ êµ¬ì¡° ì‚¬ìš©")
        
        model.eval()
        
        # Step 2: PyTorch â†’ ONNX
        print("2. PyTorch â†’ ONNX ë³€í™˜...")
        input_shape = (1, 3, 224, 224)
        dummy_input = torch.randn(input_shape)
        
        onnx_path = "emergency_model.onnx"
        torch.onnx.export(
            model, 
            dummy_input, 
            onnx_path,
            export_params=True,
            opset_version=11,
            do_constant_folding=True,
            input_names=['input'],
            output_names=['output'],
            dynamic_axes={
                'input': {0: 'batch_size'},
                'output': {0: 'batch_size'}
            }
        )
        print(f"âœ“ ONNX ëª¨ë¸ ìƒì„±: {onnx_path}")
        
        # Step 3: ONNX â†’ TensorFlow
        print("3. ONNX â†’ TensorFlow ë³€í™˜...")
        onnx_model = onnx.load(onnx_path)
        tf_model = onnx_tf.backend.prepare(onnx_model)
        
        tf_model_path = "emergency_model_tf"
        tf_model.export_graph(tf_model_path)
        print(f"âœ“ TensorFlow ëª¨ë¸ ìƒì„±: {tf_model_path}")
        
        # Step 4: TensorFlow â†’ TensorFlow Lite
        print("4. TensorFlow â†’ TensorFlow Lite ë³€í™˜...")
        
        # ì €ì¥ëœ ëª¨ë¸ì—ì„œ TFLite ì»¨ë²„í„° ìƒì„±
        converter = tf.lite.TFLiteConverter.from_saved_model(tf_model_path)
        
        # ìµœì í™” ì„¤ì •
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        converter.target_spec.supported_types = [tf.float16]  # Float16 ì–‘ìí™”
        
        # ë³€í™˜ ì‹¤í–‰
        tflite_model = converter.convert()
        
        # assets ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        # TFLite ëª¨ë¸ ì €ì¥
        with open(output_path, 'wb') as f:
            f.write(tflite_model)
        
        print(f"âœ“ TensorFlow Lite ëª¨ë¸ ìƒì„±: {output_path}")
        
        # Step 5: ëª¨ë¸ í…ŒìŠ¤íŠ¸
        print("5. TensorFlow Lite ëª¨ë¸ í…ŒìŠ¤íŠ¸...")
        test_tflite_model(output_path)
        
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        try:
            os.remove(onnx_path)
            import shutil
            shutil.rmtree(tf_model_path)
            print("âœ“ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")
        except:
            pass
        
        print("\nğŸ‰ PyTorch â†’ TensorFlow Lite ë³€í™˜ ì™„ë£Œ!")
        return True
        
    except Exception as e:
        print(f"âŒ ë³€í™˜ ì‹¤íŒ¨: {e}")
        print("\ní•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”:")
        print("pip install onnx onnx-tf tensorflow")
        return False

def test_tflite_model(tflite_path):
    """TensorFlow Lite ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    try:
        # TFLite ì¸í„°í”„ë¦¬í„° ìƒì„±
        interpreter = tf.lite.Interpreter(model_path=tflite_path)
        interpreter.allocate_tensors()
        
        # ì…ë ¥/ì¶œë ¥ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        
        print(f"âœ“ ì…ë ¥ í˜•íƒœ: {input_details[0]['shape']}")
        print(f"âœ“ ì¶œë ¥ í˜•íƒœ: {output_details[0]['shape']}")
        
        # í…ŒìŠ¤íŠ¸ ì…ë ¥ ìƒì„±
        input_shape = input_details[0]['shape']
        input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)
        
        # ì¶”ë¡  ì‹¤í–‰
        interpreter.set_tensor(input_details[0]['index'], input_data)
        interpreter.invoke()
        
        # ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
        output_data = interpreter.get_tensor(output_details[0]['index'])
        print(f"âœ“ ì¶”ë¡  ì„±ê³µ - ì¶œë ¥: {output_data.flatten()}")
        
        # í™•ë¥ ë¡œ ë³€í™˜
        probabilities = tf.nn.softmax(output_data).numpy()
        print(f"âœ“ í™•ë¥ : {probabilities.flatten()}")
        
        return True
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

if __name__ == "__main__":
    convert_pytorch_to_tflite() 